{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tsEvIIBbjG1_"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import os\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = \"/content/drive/MyDrive/Speech Audio Datasets\"\n",
        "\n",
        "EMOTION_LABELS = {\n",
        "    0: \"neutral\",\n",
        "    1: \"calm\",\n",
        "    2: \"happy\",\n",
        "    3: \"sad\",\n",
        "    4: \"angry\",\n",
        "    5: \"fearful\",\n",
        "    6: \"disgust\",\n",
        "    7: \"surprised\"\n",
        "}\n",
        "\n",
        "FEATURE_MATRIX_PATH = \"X.npy\"\n",
        "LABELS_PATH = \"y.npy\"\n",
        "MODEL_PATH = \"ser_model.pkl\"\n",
        "\n",
        "\n",
        "def extract_features(file_path):\n",
        "\n",
        "    signal, sr = librosa.load(file_path, sr=16000)\n",
        "    signal = librosa.util.normalize(signal)\n",
        "\n",
        "    mfccs = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=13)\n",
        "    delta_mfccs = librosa.feature.delta(mfccs)\n",
        "    # delta2_mfccs = librosa.feature.delta(mfccs, order=2)\n",
        "    pitches, magnitudes = librosa.core.piptrack(y=signal, sr=sr)\n",
        "    pitch = np.max(pitches, axis=0)\n",
        "    energy = librosa.feature.rms(y=signal)\n",
        "    zcr = librosa.feature.zero_crossing_rate(y=signal)\n",
        "    # spectral_contrast = librosa.feature.spectral_contrast(y=signal, sr=sr)\n",
        "    # chroma = librosa.feature.chroma_stft(y=signal, sr=sr)\n",
        "    teo = np.zeros(len(signal) - 2)\n",
        "    for i in range(1, len(signal) - 1):\n",
        "        teo[i-1] = signal[i]**2 - signal[i-1] * signal[i+1]\n",
        "\n",
        "\n",
        "    mfccs_mean = np.mean(mfccs, axis=1)\n",
        "    mfccs_std = np.std(mfccs, axis=1)\n",
        "\n",
        "    delta_mfccs_mean = np.mean(delta_mfccs, axis=1)\n",
        "    delta_mfccs_std =np.std(delta_mfccs, axis=1)\n",
        "\n",
        "    # delta2_mfccs_mean = np.mean(delta2_mfccs, axis=1)\n",
        "    # delta2_mfccs_std = np.std(delta2_mfccs, axis=1)\n",
        "\n",
        "    pitch_median = np.median(pitch)\n",
        "    pitch_std = np.std(pitch)\n",
        "\n",
        "    energy_mean = np.mean(energy)\n",
        "    energy_std = np.std(energy)\n",
        "\n",
        "    zcr_mean = np.mean(zcr)\n",
        "    zcr_std = np.std(zcr)\n",
        "\n",
        "    # spectral_contrast_mean = np.mean(spectral_contrast, axis=1)\n",
        "    # spectral_contrast_std = np.std(spectral_contrast, axis=1)\n",
        "\n",
        "    # chroma_mean = np.mean(chroma, axis=1)\n",
        "    # chroma_std = np.std(chroma, axis=1)\n",
        "\n",
        "    teo_mean = np.mean(teo)\n",
        "    teo_std = np.std(teo)\n",
        "\n",
        "\n",
        "    return np.hstack([\n",
        "        mfccs_mean, mfccs_std,\n",
        "        delta_mfccs_mean, delta_mfccs_std,\n",
        "        # delta2_mfccs_mean,  delta2_mfccs_std,\n",
        "        pitch_median, pitch_std,\n",
        "        energy_mean, energy_std,\n",
        "        zcr_mean, zcr_std,\n",
        "        # spectral_contrast_mean, spectral_contrast_std,\n",
        "        # chroma_mean, chroma_std\n",
        "        teo_mean, teo_std\n",
        "    ])\n",
        "\n",
        "def prepare_dataset():\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    for root, _, files in os.walk(DATASET_PATH):\n",
        "        for file in files:\n",
        "            if file.endswith(\".wav\"):\n",
        "                file_path = os.path.join(root, file)\n",
        "\n",
        "                features.append(extract_features(file_path))\n",
        "\n",
        "                emotion_code = int(file.split(\"-\")[2])\n",
        "                labels.append(emotion_code - 1)\n",
        "\n",
        "                print(f\"Processed: {file} â†’ Emotion: {labels[-1]}\")\n",
        "\n",
        "    np.save(FEATURE_MATRIX_PATH, np.array(features))\n",
        "    np.save(LABELS_PATH, np.array(labels))\n",
        "    print(f\"Saved features to {FEATURE_MATRIX_PATH} and {LABELS_PATH}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, labels):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "\n",
        "    ax = sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                     xticklabels=labels, yticklabels=labels,\n",
        "                     linewidths=1, linecolor='black', square=True,\n",
        "                     cbar_kws={\"orientation\": \"vertical\"})\n",
        "\n",
        "    ax.xaxis.tick_top()\n",
        "    ax.xaxis.set_label_position('top')\n",
        "\n",
        "    plt.xlabel(\"Predicted Label\", fontsize=12, labelpad=10)\n",
        "    plt.ylabel(\"True Label\", fontsize=12, labelpad=10)\n",
        "    plt.title(\"Confusion Matrix\", fontsize=14, pad=20)\n",
        "\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.yticks(rotation=0)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def train_model():\n",
        "    X = np.load(FEATURE_MATRIX_PATH)\n",
        "    y = np.load(LABELS_PATH)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # class_weight = {0: 1.061, 1: 2.0, 2: 0.905, 3: 0.905, 4: 0.905, 5: 0.905, 6: 0.905, 7: 0.905} only if calm dosent find its grip after training slap him with this\n",
        "    model = SVC(kernel=\"linear\", C=1.0, class_weight= \"balanced\")\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    # print(\"Confusion Matrix:\")\n",
        "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred, digits=4))\n",
        "    print(\"Confusion Matrix:\")\n",
        "    plot_confusion_matrix(cm, list(EMOTION_LABELS.values()))\n",
        "\n",
        "\n",
        "    joblib.dump(model, MODEL_PATH)\n",
        "    joblib.dump(scaler, \"scaler.pkl\")\n",
        "    print(f\"Model saved to {MODEL_PATH}\")\n",
        "    print(\"Scaler saved to scaler.pkl\")\n",
        "\n",
        "def predict_emotion(file_path):\n",
        "\n",
        "    model = joblib.load(MODEL_PATH)\n",
        "\n",
        "    scaler = joblib.load(\"scaler.pkl\")\n",
        "    features = extract_features(file_path)\n",
        "    features = scaler.transform([features])\n",
        "    emotion_code = model.predict(features)[0]\n",
        "    return EMOTION_LABELS[emotion_code]\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    prepare_dataset()\n",
        "    train_model()\n",
        "\n",
        "# print(\"\\nGive me an audio file, and I'll tell you its emotions!\")\n",
        "# xz = input(\"Enter file path here: \")\n",
        "# print(f\"\\nYour speech conveys '{predict_emotion(xz)}' emotion!\")\n"
      ],
      "metadata": {
        "id": "S8AvRbayjNme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_dataset():\n",
        "    emotion_counts = {i: 0 for i in range(8)}\n",
        "    for root,_, files in os.walk(DATASET_PATH):\n",
        "      for file in files:\n",
        "        if file.endswith(\".wav\"):\n",
        "            emotion_code = int(file.split(\"-\")[2]) - 1\n",
        "            emotion_counts [emotion_code] += 1\n",
        "    total = sum(emotion_counts.values())\n",
        "    print(f\"Total files: {total}\")\n",
        "    for code, count in emotion_counts.items():\n",
        "      print (f\" {EMOTION_LABELS [code]}: {count} files\")\n",
        "check_dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPCRZP675wzt",
        "outputId": "570b7441-aeb3-4c67-e3c4-1d378e3e4d9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total files: 5920\n",
            " neutral: 816 files\n",
            " calm: 192 files\n",
            " happy: 852 files\n",
            " sad: 852 files\n",
            " angry: 852 files\n",
            " fearful: 852 files\n",
            " disgust: 852 files\n",
            " surprised: 652 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nGive me an audio file, and I'll tell you its emotions!\")\n",
        "xz = input(\"Enter file path here: \")\n",
        "print(f\"\\nYour speech conveys '{predict_emotion(xz)}' emotion!\")"
      ],
      "metadata": {
        "id": "V7x8KK8e5uz_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}